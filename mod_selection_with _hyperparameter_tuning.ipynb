{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aabb78f-a4e3-4800-ad3c-581eac544c84",
   "metadata": {},
   "source": [
    "### Import Nessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0395af-c021-433f-b051-197f4b2e7b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abcbfff5-5995-4b0b-9522-51261a65da06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f24528-8b10-4a73-b334-88546b87efed",
   "metadata": {},
   "source": [
    "###  Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3021b85-f795-46c0-a57d-a174341d90a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_location</th>\n",
       "      <th>trip_start_timestamp_day</th>\n",
       "      <th>trip_start_timestamp_month</th>\n",
       "      <th>trip_start_timestamp_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08ce1d75a8a36df6f00823d64033c5042b79ec8b</td>\n",
       "      <td>b7eb3d8ccfb18e383435f51a87024fc0d3503a6fd90a66...</td>\n",
       "      <td>2019-01-14 18:45:00+00:00</td>\n",
       "      <td>2019-01-14 19:00:00+00:00</td>\n",
       "      <td>900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.703133e+10</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Taxi Affiliation Services</td>\n",
       "      <td>41.859350</td>\n",
       "      <td>-87.617358</td>\n",
       "      <td>POINT (-87.6173580061 41.859349715)</td>\n",
       "      <td>41.893216</td>\n",
       "      <td>-87.637844</td>\n",
       "      <td>POINT (-87.6378442095 41.8932163595)</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eb190a4d5e5facee2b4ef5b0d0ed0f08932113c</td>\n",
       "      <td>d1cb0b38e64d922ac1b61791a9cc03cd203fee1cfbef86...</td>\n",
       "      <td>2019-03-07 05:45:00+00:00</td>\n",
       "      <td>2019-03-07 05:45:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Patriot Taxi Dba Peace Taxi Associat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cce2d0ec80c9f7cdcb2c7a68b95de6c0d93dfa3e</td>\n",
       "      <td>ecfb6f2cdce5d4c4e80218f58070ae719060ee47e648f4...</td>\n",
       "      <td>2019-01-17 21:30:00+00:00</td>\n",
       "      <td>2019-01-17 22:00:00+00:00</td>\n",
       "      <td>1200</td>\n",
       "      <td>14.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Top Cab Affiliation</td>\n",
       "      <td>41.980264</td>\n",
       "      <td>-87.913625</td>\n",
       "      <td>POINT (-87.913624596 41.9802643146)</td>\n",
       "      <td>41.901207</td>\n",
       "      <td>-87.676356</td>\n",
       "      <td>POINT (-87.6763559892 41.90120699410001)</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7d7d3218828b6f3cf18358447a13f4c174b2837a</td>\n",
       "      <td>ff8391eff75559d6fd22b704d4b2c69422ca8dc8ed0ac4...</td>\n",
       "      <td>2019-03-13 07:00:00+00:00</td>\n",
       "      <td>2019-03-13 07:15:00+00:00</td>\n",
       "      <td>519</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>1.703184e+10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Sun Taxi</td>\n",
       "      <td>41.891972</td>\n",
       "      <td>-87.612945</td>\n",
       "      <td>POINT (-87.6129454143 41.8919715078)</td>\n",
       "      <td>41.880994</td>\n",
       "      <td>-87.632746</td>\n",
       "      <td>POINT (-87.6327464887 41.8809944707)</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37950728f711fe741f2dd9576633750093bb8a72</td>\n",
       "      <td>bed9183af3fecf2a370b57b32766defe663eb2f990a744...</td>\n",
       "      <td>2019-02-13 07:30:00+00:00</td>\n",
       "      <td>2019-02-13 07:45:00+00:00</td>\n",
       "      <td>1140</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.703108e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Medallion Leasin</td>\n",
       "      <td>41.905858</td>\n",
       "      <td>-87.630865</td>\n",
       "      <td>POINT (-87.6308650266 41.9058577688)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 unique_key  \\\n",
       "0  08ce1d75a8a36df6f00823d64033c5042b79ec8b   \n",
       "1  9eb190a4d5e5facee2b4ef5b0d0ed0f08932113c   \n",
       "2  cce2d0ec80c9f7cdcb2c7a68b95de6c0d93dfa3e   \n",
       "3  7d7d3218828b6f3cf18358447a13f4c174b2837a   \n",
       "4  37950728f711fe741f2dd9576633750093bb8a72   \n",
       "\n",
       "                                             taxi_id  \\\n",
       "0  b7eb3d8ccfb18e383435f51a87024fc0d3503a6fd90a66...   \n",
       "1  d1cb0b38e64d922ac1b61791a9cc03cd203fee1cfbef86...   \n",
       "2  ecfb6f2cdce5d4c4e80218f58070ae719060ee47e648f4...   \n",
       "3  ff8391eff75559d6fd22b704d4b2c69422ca8dc8ed0ac4...   \n",
       "4  bed9183af3fecf2a370b57b32766defe663eb2f990a744...   \n",
       "\n",
       "        trip_start_timestamp         trip_end_timestamp  trip_seconds  \\\n",
       "0  2019-01-14 18:45:00+00:00  2019-01-14 19:00:00+00:00           900   \n",
       "1  2019-03-07 05:45:00+00:00  2019-03-07 05:45:00+00:00             3   \n",
       "2  2019-01-17 21:30:00+00:00  2019-01-17 22:00:00+00:00          1200   \n",
       "3  2019-03-13 07:00:00+00:00  2019-03-13 07:15:00+00:00           519   \n",
       "4  2019-02-13 07:30:00+00:00  2019-02-13 07:45:00+00:00          1140   \n",
       "\n",
       "   trip_miles  pickup_census_tract  dropoff_census_tract  \\\n",
       "0        0.00         1.703133e+10          1.703108e+10   \n",
       "1        0.02                  NaN                   NaN   \n",
       "2       14.70                  NaN                   NaN   \n",
       "3        1.29         1.703108e+10          1.703184e+10   \n",
       "4        4.10         1.703108e+10                   NaN   \n",
       "\n",
       "   pickup_community_area  dropoff_community_area  ...  \\\n",
       "0                   33.0                     8.0  ...   \n",
       "1                    NaN                     NaN  ...   \n",
       "2                   76.0                    24.0  ...   \n",
       "3                    8.0                    32.0  ...   \n",
       "4                    8.0                     NaN  ...   \n",
       "\n",
       "                                company  pickup_latitude  pickup_longitude  \\\n",
       "0             Taxi Affiliation Services        41.859350        -87.617358   \n",
       "1  Patriot Taxi Dba Peace Taxi Associat              NaN               NaN   \n",
       "2                   Top Cab Affiliation        41.980264        -87.913625   \n",
       "3                              Sun Taxi        41.891972        -87.612945   \n",
       "4                      Medallion Leasin        41.905858        -87.630865   \n",
       "\n",
       "                        pickup_location  dropoff_latitude dropoff_longitude  \\\n",
       "0   POINT (-87.6173580061 41.859349715)         41.893216        -87.637844   \n",
       "1                                   NaN               NaN               NaN   \n",
       "2   POINT (-87.913624596 41.9802643146)         41.901207        -87.676356   \n",
       "3  POINT (-87.6129454143 41.8919715078)         41.880994        -87.632746   \n",
       "4  POINT (-87.6308650266 41.9058577688)               NaN               NaN   \n",
       "\n",
       "                           dropoff_location  trip_start_timestamp_day  \\\n",
       "0      POINT (-87.6378442095 41.8932163595)                        14   \n",
       "1                                       NaN                         7   \n",
       "2  POINT (-87.6763559892 41.90120699410001)                        17   \n",
       "3      POINT (-87.6327464887 41.8809944707)                        13   \n",
       "4                                       NaN                        13   \n",
       "\n",
       "   trip_start_timestamp_month trip_start_timestamp_hour  \n",
       "0                           1                        18  \n",
       "1                           3                         5  \n",
       "2                           1                        21  \n",
       "3                           3                         7  \n",
       "4                           2                         7  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading CSV file in the GCS bucket\n",
    "gcs_path = 'gs://cab_bucket/cab-gcp-vertex-pipelines1/data/Final_Chicago_Train.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(gcs_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9497824b-5dc3-4280-b4e4-2f6ec14ba52b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the 'trip_start_timestamp' to datetime if it's not already.\n",
    "df['trip_start_timestamp'] = pd.to_datetime(df['trip_start_timestamp'])\n",
    "\n",
    "# Extract hour, day, and month from the timestamp\n",
    "df['trip_start_hour'] = df['trip_start_timestamp'].dt.hour\n",
    "df['trip_start_day'] = df['trip_start_timestamp'].dt.day\n",
    "df['trip_start_month'] = df['trip_start_timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52defa5e-dc13-4e0a-8bc5-92f3f07f628e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['unique_key', 'taxi_id', 'trip_start_timestamp', \n",
    "                   'trip_end_timestamp', 'dropoff_location', 'pickup_location']\n",
    "# Dropping unnecessary columns \n",
    "df= df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2094d-e2e7-4246-9a49-c0a5eeb870c6",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23d1cae-314f-4674-9c1f-fe5a73d4559e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def one_hot_encode(values, num_categories):\n",
    "    \"\"\"One-hot encode the values.\"\"\"\n",
    "    categories = sorted(set(values.dropna()))  # Handle NaN by dropping\n",
    "    one_hot_encoded = []\n",
    "    for v in values:\n",
    "        encoding = [1 if v == category else 0 for category in categories]\n",
    "        one_hot_encoded.append(encoding)\n",
    "    return pd.DataFrame(one_hot_encoded, columns=[f\"{values.name}_{c}\" for c in categories], index=values.index)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    numerical_features = ['trip_miles', 'trip_seconds', 'tips', 'tolls', 'extras', 'trip_total']\n",
    "    bucket_features = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "    categorical_numerical_features = [\n",
    "        'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
    "        'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
    "        'dropoff_community_area'\n",
    "    ]\n",
    "    categorical_string_features = ['payment_type', 'company']\n",
    "    \n",
    "    # Handling missing values and scaling numerical features\n",
    "    for feature in numerical_features:\n",
    "        df[feature] = SimpleImputer(strategy='mean').fit_transform(df[[feature]])\n",
    "        df[feature] = StandardScaler().fit_transform(df[[feature]])\n",
    "    \n",
    "    # Bucketizing geographical features\n",
    "    for feature in bucket_features:\n",
    "        df[feature] = SimpleImputer(strategy='mean').fit_transform(df[[feature]])\n",
    "        discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "        df[feature] = discretizer.fit_transform(df[[feature]])\n",
    "    \n",
    "    # One-hot encoding for categorical string features\n",
    "    for feature in categorical_string_features:\n",
    "        df_filled = SimpleImputer(strategy='constant', fill_value='missing').fit_transform(df[[feature]].astype(str))\n",
    "        df_encoded = one_hot_encode(pd.Series(df_filled.flatten(), name=feature), num_categories=None)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "        df.drop(columns=[feature], inplace=True)\n",
    "    \n",
    "    # One-hot encoding for categorical numerical features\n",
    "    for feature in categorical_numerical_features:\n",
    "        df_filled = SimpleImputer(strategy='most_frequent').fit_transform(df[[feature]].astype(str))\n",
    "        df_encoded = one_hot_encode(pd.Series(df_filled.flatten(), name=feature), num_categories=None)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "        df.drop(columns=[feature], inplace=True)\n",
    "    \n",
    "    # Fill missing values for the label (fare)\n",
    "    df['fare'] = SimpleImputer(strategy='mean').fit_transform(df[['fare']])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72d22093-77ca-49f5-9cf1-54c42d19bef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>fare</th>\n",
       "      <th>tips</th>\n",
       "      <th>tolls</th>\n",
       "      <th>extras</th>\n",
       "      <th>trip_total</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>dropoff_community_area_71.0</th>\n",
       "      <th>dropoff_community_area_72.0</th>\n",
       "      <th>dropoff_community_area_73.0</th>\n",
       "      <th>dropoff_community_area_74.0</th>\n",
       "      <th>dropoff_community_area_75.0</th>\n",
       "      <th>dropoff_community_area_76.0</th>\n",
       "      <th>dropoff_community_area_77.0</th>\n",
       "      <th>dropoff_community_area_8.0</th>\n",
       "      <th>dropoff_community_area_9.0</th>\n",
       "      <th>dropoff_community_area_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052148</td>\n",
       "      <td>-0.613203</td>\n",
       "      <td>11.00</td>\n",
       "      <td>-0.602814</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.038608</td>\n",
       "      <td>-0.097897</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.560844</td>\n",
       "      <td>-0.609551</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-0.602814</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.038608</td>\n",
       "      <td>-0.221185</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257163</td>\n",
       "      <td>2.071362</td>\n",
       "      <td>36.75</td>\n",
       "      <td>3.591021</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>0.080586</td>\n",
       "      <td>0.569445</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.208220</td>\n",
       "      <td>-0.377619</td>\n",
       "      <td>7.50</td>\n",
       "      <td>-0.087178</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.038608</td>\n",
       "      <td>-0.121760</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216160</td>\n",
       "      <td>0.135553</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0.944092</td>\n",
       "      <td>-0.009487</td>\n",
       "      <td>-0.038608</td>\n",
       "      <td>0.037321</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_seconds  trip_miles   fare      tips     tolls    extras  trip_total  \\\n",
       "0      0.052148   -0.613203  11.00 -0.602814 -0.009487 -0.038608   -0.097897   \n",
       "1     -0.560844   -0.609551   3.25 -0.602814 -0.009487 -0.038608   -0.221185   \n",
       "2      0.257163    2.071362  36.75  3.591021 -0.009487  0.080586    0.569445   \n",
       "3     -0.208220   -0.377619   7.50 -0.087178 -0.009487 -0.038608   -0.121760   \n",
       "4      0.216160    0.135553  14.50  0.944092 -0.009487 -0.038608    0.037321   \n",
       "\n",
       "   pickup_latitude  pickup_longitude  dropoff_latitude  ...  \\\n",
       "0              5.0               7.0               6.0  ...   \n",
       "1              6.0               6.0               6.0  ...   \n",
       "2              8.0               0.0               6.0  ...   \n",
       "3              6.0               7.0               6.0  ...   \n",
       "4              6.0               7.0               6.0  ...   \n",
       "\n",
       "   dropoff_community_area_71.0  dropoff_community_area_72.0  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   dropoff_community_area_73.0  dropoff_community_area_74.0  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   dropoff_community_area_75.0  dropoff_community_area_76.0  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   dropoff_community_area_77.0  dropoff_community_area_8.0  \\\n",
       "0                            0                           1   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "\n",
       "   dropoff_community_area_9.0  dropoff_community_area_nan  \n",
       "0                           0                           0  \n",
       "1                           0                           1  \n",
       "2                           0                           0  \n",
       "3                           0                           0  \n",
       "4                           0                           1  \n",
       "\n",
       "[5 rows x 644 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming your DataFrame after dropping columns is named df\n",
    "df_processed = preprocess_data(df)\n",
    "\n",
    "# Now you can display the processed DataFrame\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "906623fe-bc89-4806-87cd-03246c5da323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trip_seconds', 'trip_miles', 'pickup_census_tract',\n",
       "       'dropoff_census_tract', 'pickup_community_area',\n",
       "       'dropoff_community_area', 'fare', 'tips', 'tolls', 'extras',\n",
       "       'trip_total', 'payment_type', 'company', 'pickup_latitude',\n",
       "       'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',\n",
       "       'trip_start_timestamp_day', 'trip_start_timestamp_month',\n",
       "       'trip_start_timestamp_hour', 'trip_start_hour', 'trip_start_day',\n",
       "       'trip_start_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e36b9-68e1-469f-9ce0-f7d4d0933870",
   "metadata": {},
   "source": [
    "### Defining X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6776bd0f-041a-4641-9b14-c0d6c80376ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y =df_processed['fare']\n",
    "# Dropping unnecessary columns \n",
    "X= df_processed.drop(columns='fare')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae7cbb-3b47-480e-9c06-8c9dbca9a8d2",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2593fcb1-56dc-44ee-b24f-c37b5abb1902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615e01d-df71-4bb2-ab5c-5aea2228e03c",
   "metadata": {},
   "source": [
    "### Fitting the model and evaluating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d282ec5-9a15-407c-9e8a-585154cb96e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 2438653910139406.0000, RMSE: 49382728.8649, R2: -12413898526467.4023\n",
      "Decision Tree - MSE: 1981.1061, RMSE: 44.5096, R2: -9.0848\n",
      "Random Forest - MSE: 3948.6124, RMSE: 62.8380, R2: -19.1003\n",
      "Gradient Boosting - MSE: 6124.0131, RMSE: 78.2561, R2: -30.1741\n",
      "ANN - MSE: 2.0556, RMSE: 1.4337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Define the ANN functions\n",
    "def _build_ann_model():\n",
    "    \"\"\"Creates a simple artificial neural network model.\"\"\"\n",
    "    ann_model = MLPRegressor(hidden_layer_sizes=(100, 70, 50, 20),\n",
    "                             activation='relu',\n",
    "                             solver='adam',\n",
    "                             learning_rate_init=0.0005,\n",
    "                             random_state=42)\n",
    "    return ann_model\n",
    "\n",
    "def _train_ann_model(model, train_data, train_labels):\n",
    "    \"\"\"Trains the artificial neural network model.\"\"\"\n",
    "    model.fit(train_data, train_labels)\n",
    "\n",
    "def _evaluate_ann_model(model, eval_data, eval_labels):\n",
    "    \"\"\"Evaluates the artificial neural network model.\"\"\"\n",
    "    eval_predictions = model.predict(eval_data)\n",
    "    mse = ((eval_predictions - eval_labels) ** 2).mean()\n",
    "    return mse\n",
    "\n",
    "# Initialize models including the ANN model\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"ANN\": _build_ann_model()  \n",
    "}\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    if isinstance(model, MLPRegressor):\n",
    "        # Train and evaluate ANN model separately\n",
    "        _train_ann_model(model, X_train, y_train)\n",
    "        mse = _evaluate_ann_model(model, X_test, y_test)\n",
    "        return mse, np.sqrt(mse), None  # No R2 score for ANN model\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        return mse, rmse, r2\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    mse, rmse, r2 = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results[model_name] = {\"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "# Print the results\n",
    "for model_name, metrics in results.items():\n",
    "    if metrics['R2'] is not None:\n",
    "        print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, RMSE: {metrics['RMSE']:.4f}, R2: {metrics['R2']:.4f}\")\n",
    "    else:\n",
    "        print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, RMSE: {metrics['RMSE']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c3888-ba8c-4c07-93c6-03ee12f9ce6e",
   "metadata": {},
   "source": [
    "##### Here ANN model is giving the best result compared to other models. So we are selecting the ANN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf95a6-3bd7-434d-a274-f3c268255f8b",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694fd0be-6275-4c3b-a3fa-95c89f1f5fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Define the ANN functions\n",
    "def _build_ann_model():\n",
    "    \"\"\"Creates a simple artificial neural network model.\"\"\"\n",
    "    ann_model = MLPRegressor(random_state=42)\n",
    "    return ann_model\n",
    "def _train_ann_model(model, train_data, train_labels):\n",
    "    \"\"\"Trains the artificial neural network model.\"\"\"\n",
    "    model.fit(train_data, train_labels)\n",
    "def _evaluate_ann_model(model, eval_data, eval_labels):\n",
    "    \"\"\"Evaluates the artificial neural network model.\"\"\"\n",
    "    eval_predictions = model.predict(eval_data)\n",
    "    mse = mean_squared_error(eval_labels, eval_predictions)\n",
    "    return mse\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    \"Linear Regression\": {},\n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 10, 20]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 10, 20]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    \"ANN\": {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 70, 50, 20)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'learning_rate_init': [0.001, 0.0005, 0.0001]\n",
    "    }\n",
    "}\n",
    "# Initialize models including the ANN model\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"ANN\": _build_ann_model()  # Include the ANN model here\n",
    "}\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(model, param_grid, X_train, X_test, y_train, y_test):\n",
    "    if isinstance(model, MLPRegressor):\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        _train_ann_model(best_model, X_train, y_train)\n",
    "        mse = _evaluate_ann_model(best_model, X_test, y_test)\n",
    "        return mse, np.sqrt(mse), None, best_model\n",
    "    else:\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        return mse, rmse, r2, best_model\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    mse, rmse, r2, best_model = evaluate_model(model, param_grid, X_train, X_test, y_train, y_test)\n",
    "    results[model_name] = {\"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "    best_models[model_name] = best_model\n",
    "\n",
    "# Print the results\n",
    "for model_name, metrics in results.items():\n",
    "    if metrics['R2'] is not None:\n",
    "        print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, RMSE: {metrics['RMSE']:.4f}, R2: {metrics['R2']:.4f}\")\n",
    "    else:\n",
    "        print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, RMSE: {metrics['RMSE']:.4f}\")\n",
    "\n",
    "# Print the best model for each algorithm\n",
    "for model_name, best_model in best_models.items():\n",
    "    print(f\"Best model for {model_name}: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63935ce4-fcd0-4fed-aea4-77c271bf86da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d97f2-aa2a-4dac-9a50-fc5044bc561d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a4eda-94cd-479f-9b53-f606c4cbcd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04fee8-2b70-4f84-8f39-4588f5b3e9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e23e0-ac02-4f68-b2d2-d1afd4fe4770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091f4b1-1c0e-44a2-8746-cff7a03c071e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b183b4b-eb0f-4319-99e5-40bb669823cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a7f35-c085-419c-aea1-cd026c074da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad9e02-d585-4b9f-9b2a-3dbe026a828e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5227e8d-4ef5-48e2-afe6-94f1ef5103ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb40779-2c5d-413a-8c25-9017b593ece8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4acab-637e-493b-8c76-c512a3b67ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
